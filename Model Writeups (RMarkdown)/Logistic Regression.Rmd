---
title: "Logistic Regression"
author: "Stefanie Molin"
date: "`r format(Sys.Date(), '%B %d, %Y')`"
output: html_document
---

```{r template-setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

# load the case study library
library(modelAnalyzeR)
library(dplyr)

# all data will be loaded in the parent document and referenced within each of the child sections
```

### Logistic Regression
Logistic regression despite its name is a method of classification. It allows us to predict which class an observation belongs to (think: alert or not alert). We can also use it to predict the probability it is an alert by defining a threshold above which it is an alert. For this model, the best performing set of features was: the last 25 data points, dummy-encoded KPI's, exponential weights for TS, linear weights for AS, and including summary statistics (mean, variance, min, max). Everything was min-max scaled ($value = \frac{value - min(x)}{max(x) - min(x)}$).

*Note that this method will be performed in Python using Scikit-learn and the Jupyter notebook is available in the repo.*

```{r format_data_to_pass_to_python, echo=FALSE, eval=FALSE}
python_AS_data <- prep_AS_for_python(AS_data, days = 25)
python_TS_data <- prep_TS_for_python(TS_data, days = 25)
python_RexT_data <- prep_RexT_for_python(RexT_data, days = 30)

# write to files for transfer
write.csv(x = python_AS_data, file = params$python_AS_file, row.names = FALSE)
write.csv(x = python_TS_data, file = params$python_TS_file, row.names = FALSE)
write.csv(x = python_RexT_data, file = params$python_RexT_file, row.names = FALSE)
```

#### Results
Overall, we achieve a `F1-score` of 0.74 for AS, 0.89 for TS, and 0.96 for RexT; however, when we separate this out by class (alert vs. not-alert), we see that our performance is being carried by the majority class (not alert). Isolating the alert class, our `F1-score` for AS is 0.21 (!), 0.18 for TS (!), and 0.83 for RexT. Figure \ref{fig:log_reg_conf_mat} shows the confusion matrix on the test set using thresholds of 80% for AS, 70% for TS, and 50% for RexT.

\begin{figure}[h!]
\centering
  \includegraphics[width=1.0\textwidth]{images/logistic_regression_conf_matrix.png}
\caption{Logistic regression confusion matrix}
\label{fig:log_reg_conf_mat}
\end{figure}


#### ROC Curve
Note that although we have a dip in the ROC curve for TS (see Figure \ref{fig:log_reg_roc_curve}), it is in the range of false positive rate greater than 20% which is already way more than we can tolerate. Essentially, we only care about maximizing the area under the ROC curve from 0% FPR to 20% FPR.

\begin{figure}[h!]
\centering
  \includegraphics[width=1.0\textwidth]{images/logistic_regression_roc.png}
\caption{Logistic regression ROC curve}
\label{fig:log_reg_roc_curve}
\end{figure}


#### Alogrithm Complexity  
See `Scikit-learn` documentation.

#### Conclusions
This performed pretty well on the RexT data, but that is most likely due to the relatively few data points we have. The performance is pretty weak for AS and TS data; perhaps with more data to average the opinions of for those series, we can obtain better results, but for now, we should look to other methods.

