{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Models for SCOPE: Model Name Here\n",
    "Models will be coded here, but the official write up will be in the RMarkdown document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data files\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pymodelutils import utils\n",
    "\n",
    "logs = pd.read_csv(\"data/metis_logs.csv\")\n",
    "logs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter down to show the average opinion (0 means no alert, 1 means alert)\n",
    "logs['run_date'] = logs['run_date'].astype('datetime64[ns]')\n",
    "logs['is_alert'] = (np.where(logs['is_alert'] == 'f', 0, 1))\n",
    "logs = logs.groupby(['series', 'kpi', 'run_date']).mean().round(0).reset_index()\n",
    "logs['is_campaign'] = np.where(logs['campaign_id'] > 0, 1, 0)\n",
    "logs = logs.drop(columns=['client_id', 'partner_id', 'campaign_id'])\n",
    "logs['is_alert'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AS_data = pd.read_csv(\"data/python_AS.csv\")\n",
    "AS_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TS_data = pd.read_csv(\"data/python_TS.csv\")\n",
    "TS_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RexT_data = pd.read_csv(\"data/python_RexT.csv\")\n",
    "RexT_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Prep\n",
    "R has already filtered down the data to the days we are going to use and marked what is disqualified. We still have to handle the feature selection and one-hot encoding of select columns though. We also need to normalize it since out KPIs behave quite differently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add column for AS to tell if it is campaign level or not\n",
    "AS_data['is_campaign'] = np.where(AS_data['campaign_id'] > 0, 1, 0)\n",
    "\n",
    "# drop the data we don't need for the model or for matching back to the logs\n",
    "AS_keep_columns = ['series', 'day', 'run_date', 'kpi', 'value', 'disqualified', 'is_campaign']\n",
    "TS_keep_columns = ['series', 'day', 'run_date', 'site_type', 'event_name', \n",
    "                   'kpi', 'value', 'disqualified']\n",
    "RexT_drop_columns = ['ranking',\n",
    "                    'day_of_week',\n",
    "                    'day_of_month',\n",
    "                    'month_of_year',\n",
    "                    'day_of_year',\n",
    "                    'week_of_year']\n",
    "\n",
    "AS_data = AS_data[AS_keep_columns]\n",
    "TS_data = TS_data[TS_keep_columns]\n",
    "RexT_data = RexT_data.drop(columns=RexT_drop_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AS_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TS_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RexT_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a new column to determine how many days before the run_date the day column entry is\n",
    "# this will enable us to pivot that data into separate columns for the features of our model\n",
    "utils.prep_dates(AS_data)\n",
    "utils.prep_dates(TS_data)\n",
    "utils.prep_dates(RexT_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inner joins to logs\n",
    "AS_data = pd.merge(AS_data, logs, on=['series', 'run_date', 'kpi', 'is_campaign'], how='inner')\n",
    "TS_data = pd.merge(TS_data, logs, on=['series', 'run_date', 'kpi'], how='inner')\n",
    "RexT_data = pd.merge(RexT_data, logs, on=['series', 'run_date', 'kpi'], how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter out the disqualified data (AS and TS data only)\n",
    "AS_disqualified = AS_data[AS_data.disqualified]\n",
    "TS_disqualified = TS_data[TS_data.disqualified]\n",
    "\n",
    "# valid for model (AS and TS data only)\n",
    "valid_AS_raw = AS_data[~(AS_data.disqualified)]\n",
    "valid_TS_raw = TS_data[~(TS_data.disqualified)]\n",
    "\n",
    "# keep a copy of the raw RexT data\n",
    "RexT_data_raw = RexT_data.copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final preparations to the data shape for use in the model\n",
    "valid_AS = utils.data_prep_pipeline(valid_AS_raw.copy(), \n",
    "                                      indices=['series', 'run_date', 'kpi', 'is_campaign', 'is_alert'], \n",
    "                                      cols=['kpi'],\n",
    "                                      scaling_method=['standardize', 'min_max', 'percent_of_mean'])\n",
    "disqualified_AS = utils.data_prep_pipeline(AS_disqualified.copy(), \n",
    "                                          indices=['series', 'run_date', 'kpi', 'is_campaign', 'is_alert'], \n",
    "                                          cols=['kpi'],\n",
    "                                          scaling_method=['standardize', 'min_max', 'percent_of_mean'])\n",
    "valid_TS = utils.data_prep_pipeline(valid_TS_raw.copy(), \n",
    "                                      indices=['series', 'run_date', 'site_type', 'event_name', 'is_alert'], \n",
    "                                      cols=['site_type', 'event_name'],\n",
    "                                      scaling_method=['standardize', 'min_max', 'percent_of_mean'])\n",
    "disqualified_TS = utils.data_prep_pipeline(TS_disqualified.copy(), \n",
    "                                          indices=['series', 'run_date', 'site_type', 'event_name', 'is_alert'], \n",
    "                                          cols=['site_type', 'event_name'],\n",
    "                                          scaling_method=['standardize', 'min_max', 'percent_of_mean'])\n",
    "valid_RexT = utils.data_prep_pipeline(utils.clean_regions(RexT_data), \n",
    "                                       indices=['isCountry', 'isSubregion', 'isRegion', \n",
    "                                                'series', 'run_date', 'is_alert'], \n",
    "                                       cols=['series'],\n",
    "                                       scaling_method=['standardize', 'min_max', 'percent_of_mean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for the TS data we need to drop event_name_SITE LEVEL because it will always be the same as site_type_SITE LEVEL\n",
    "valid_TS = {key : value.drop(columns='event_name_SITE LEVEL') for key, value in valid_TS.items()}\n",
    "\n",
    "# add back missing columns for the disqualified data\n",
    "disqualified_TS['min_max']['time_delta_24'], disqualified_TS['min_max']['time_delta_25'] = (0,0)\n",
    "disqualified_TS['min_max']['site_type_SITE LEVEL'], disqualified_TS['min_max']['site_type_aios'] = (0,0)\n",
    "disqualified_TS['min_max']['time_delta_diff_23'], disqualified_TS['min_max']['time_delta_diff_24'] = (0,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_AS['min_max'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_TS['percent_of_mean'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_RexT['standardize'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling\n",
    "Now that all the data is prepped, we can start building some logistic regression models to test on. We also need to split our data into a test and train set being careful that we have an equal proportion of anomalies in each (because they are very few, we have to make sure we don't train or test the model on all the anomalies while the other gets none).\n",
    "\n",
    "### Split Data into Train and Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# scaling method to test\n",
    "AS_scaler = 'min_max'\n",
    "TS_scaler = 'min_max'\n",
    "RexT_scaler = 'min_max'\n",
    "\n",
    "# separate out data into feature matrices and target arrays\n",
    "AS_features = valid_AS[AS_scaler][[col for col in valid_AS[AS_scaler].columns \n",
    "                        if col not in ['series', 'run_date', 'is_alert']]] # this needs to be the model features\n",
    "AS_targets = valid_AS[AS_scaler]['is_alert'] # this needs to be the results from the logs (only)\n",
    "\n",
    "TS_features = valid_TS[TS_scaler][[col for col in valid_TS[TS_scaler].columns \n",
    "                        if col not in ['series', 'run_date', 'is_alert']]]\n",
    "TS_targets = valid_TS[TS_scaler]['is_alert']\n",
    "\n",
    "RexT_features = valid_RexT[RexT_scaler][[col for col in valid_RexT[RexT_scaler].columns \n",
    "                           if col not in ['run_date', 'is_alert']]]\n",
    "RexT_targets = valid_RexT[RexT_scaler]['is_alert']\n",
    "test_RexT_features = RexT_features.drop(columns=[col for col in RexT_features.columns \n",
    "                                                 if 'series' in col\n",
    "                                                or col in ['isCountry', 'isSubregion', 'isRegion']])\n",
    "\n",
    "# split into a train and test set without differences\n",
    "AS_X_train, AS_X_test, AS_y_train, AS_y_test = train_test_split(AS_features[[col for col in AS_features.columns \n",
    "                                                                             if 'diff' not in col]], \n",
    "                                                                AS_targets, \n",
    "                                                                test_size=0.2, \n",
    "                                                                random_state=25)\n",
    "TS_X_train, TS_X_test, TS_y_train, TS_y_test = train_test_split(TS_features[[col for col in TS_features.columns \n",
    "                                                                             if 'diff' not in col]], \n",
    "                                                                TS_targets, \n",
    "                                                                test_size=0.2, \n",
    "                                                                random_state=25)\n",
    "RexT_X_train, RexT_X_test, RexT_y_train, RexT_y_test = train_test_split(test_RexT_features[[col for col in \n",
    "                                                                                            test_RexT_features.columns\n",
    "                                                                                            if 'diff' not in col]], \n",
    "                                                                        RexT_targets, \n",
    "                                                                        test_size=0.5, \n",
    "                                                                        random_state=25)\n",
    "\n",
    "# split into a train and test set with differences\n",
    "AS_X_train_diff, AS_X_test_diff, AS_y_train_diff, AS_y_test_diff = train_test_split(AS_features, \n",
    "                                                                                    AS_targets, \n",
    "                                                                                    test_size=0.2, \n",
    "                                                                                    random_state=25)\n",
    "TS_X_train_diff, TS_X_test_diff, TS_y_train_diff, TS_y_test_diff = train_test_split(TS_features, \n",
    "                                                                                    TS_targets, \n",
    "                                                                                    test_size=0.2, \n",
    "                                                                                    random_state=25)\n",
    "RexT_X_train_diff, RexT_X_test_diff, RexT_y_train_diff, RexT_y_test_diff = train_test_split(test_RexT_features, \n",
    "                                                                                            RexT_targets, \n",
    "                                                                                            test_size=0.5, \n",
    "                                                                                            random_state=25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make sure that we have similar percentage of anomalies in our test and train sets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AS\n",
    "print('Total alerts in training set: ' + str(AS_y_train.sum()))\n",
    "print('Total alerts in test set: ' + str(AS_y_test.sum()))\n",
    "pd.DataFrame({'train' : AS_y_train.value_counts(normalize=True), \n",
    "              'test' : AS_y_test.value_counts(normalize=True)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TS\n",
    "print('Total alerts in training set: ' + str(TS_y_train.sum()))\n",
    "print('Total alerts in test set: ' + str(TS_y_test.sum()))\n",
    "pd.DataFrame({'train' : TS_y_train.value_counts(normalize=True), \n",
    "              'test' : TS_y_test.value_counts(normalize=True)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RexT\n",
    "print('Total alerts in training set: ' + str(RexT_y_train.sum()))\n",
    "print('Total alerts in test set: ' + str(RexT_y_test.sum()))\n",
    "pd.DataFrame({'train' : RexT_y_train.value_counts(normalize=True), \n",
    "              'test' : RexT_y_test.value_counts(normalize=True)})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
